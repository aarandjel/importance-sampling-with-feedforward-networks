{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Black_Scholes_knockout_arithmetic_asian_basket_call.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarandjel/importance-sampling-with-feedforward-networks/blob/main/Black_Scholes_knockout_arithmetic_asian_basket_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQdSDIhhIU6R"
      },
      "source": [
        "# Importance sampling for option pricing with feedforward neural networks\n",
        "\n",
        "In this Jupyter notebook, we study the problem of reducing the standard error in Monte Carlo simulations when pricing path-dependent options through suitable changes of measure which are induced by feedforward networks.\n",
        "\n",
        "We consider an arithmetic Asian basket knock-out call option in a multivariate Black-Scholes model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnMJrc31IU6j"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.linalg import norm\n",
        "from tqdm.notebook import trange\n",
        "from numpy import savetxt, loadtxt\n",
        " \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import initializers, optimizers, layers\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, Subtract, Multiply, Lambda, Add, Dot, Minimum, Maximum\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        " \n",
        "print('Python version: ', sys.version)\n",
        "print('Tensorflow version: ', tf.__version__)\n",
        "print('Keras version: ', keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW5M4HHREOGI"
      },
      "source": [
        "T = 1\n",
        "N = 252\n",
        "delta_t = T/N\n",
        "strike = 70.0\n",
        "r = 0.05\n",
        "N_assets = 10\n",
        "N_train = 3*10**5\n",
        "learnrate = 0.001\n",
        "\n",
        "L = 40.0\n",
        "U = 90.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwVSAiO0EOGI"
      },
      "source": [
        "# X_0 = np.around(np.random.uniform(low=40.0, high=50.0, size=(N_assets)), 0)\n",
        "# mu = np.around(np.random.uniform(low=0.00, high=0.10, size=(N_assets)), 4)\n",
        "# Sigma = np.around(np.random.uniform(low=-0.30, high=0.30, size=(N_assets, N_assets)), 4)\n",
        "\n",
        "# savetxt(\"mBSX_0.csv\", X_0, delimiter=\",\")\n",
        "# savetxt(\"mBSmu.csv\", mu, delimiter=\",\")\n",
        "# savetxt(\"mBSSigma.csv\", Sigma, delimiter=\",\")\n",
        "\n",
        "# X_0 = loadtxt(\"mBSX_0.csv\", delimiter=\",\")\n",
        "# mu = loadtxt(\"mBSmu.csv\", delimiter=\",\")\n",
        "# Sigma = loadtxt(\"mBSSigma.csv\", delimiter=\",\")\n",
        "\n",
        "X_0 = loadtxt(\"https://raw.githubusercontent.com/aarandjel/importance-sampling-with-feedforward-networks/main/mBSX_0.csv\", delimiter=\",\")\n",
        "mu = loadtxt(\"https://raw.githubusercontent.com/aarandjel/importance-sampling-with-feedforward-networks/main/mBSmu.csv\", delimiter=\",\")\n",
        "Sigma = loadtxt(\"https://raw.githubusercontent.com/aarandjel/importance-sampling-with-feedforward-networks/main/mBSSigma.csv\", delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RM1PqKcEOGJ"
      },
      "source": [
        "Sigmaprime = np.dot(Sigma, np.transpose(Sigma)) # This is the variance-covariance matrix of $M_{1} = \\Sigma B_{1}$\n",
        "\n",
        "volvec = np.diag(Sigmaprime)\n",
        "tilde_mu = mu - 0.5 * volvec\n",
        "\n",
        "weights = np.divide(mu, np.sqrt(np.diag(Sigmaprime)))\n",
        "weights = weights / np.sum(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxwYNvTdEOGK"
      },
      "source": [
        "# Visualizing the correlation matrix of $M_{1}$\n",
        "v = np.sqrt(np.diag(Sigmaprime))\n",
        "outer_v = np.outer(v,v)\n",
        "Rho = Sigmaprime / outer_v\n",
        "Rho[Sigmaprime == 0] = 0\n",
        "\n",
        "f, ax = plt.subplots(figsize=(9, 13))\n",
        "\n",
        "heatmap = sns.heatmap(Rho, square = True, linewidths = .5, cmap=\"RdBu\", \n",
        "                      cbar_kws = {'shrink': .4, \"ticks\" : [-1, -.5, 0, 0.5, 1]},\n",
        "                      vmin = -1, vmax = 1, annot = True, annot_kws = {\"size\": 12})\n",
        "\n",
        "ax.set_yticklabels(\"\")\n",
        "ax.set_xticklabels(\"\")\n",
        "\n",
        "sns.set_style({'xtick.bottom': True}, {'ytick.left': True})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx5IrcnDEOGK"
      },
      "source": [
        "M = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (N_assets, N)))\n",
        "\n",
        "M = M + tilde_mu[:, None] * delta_t\n",
        "M = np.cumsum(np.concatenate((np.zeros((N_assets, 1)), M), axis=1), axis=1)\n",
        "M = np.multiply(np.exp(M), X_0[:, None])\n",
        "\n",
        "basket = np.sum(np.multiply(M, weights[:, None]), axis = 0)\n",
        "    \n",
        "t = np.linspace(0, T, N+1) \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.plot(t, np.transpose(M))\n",
        "plt.plot(t, np.transpose(basket), color=\"black\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brf-Jn3DEOGL"
      },
      "source": [
        "N_sample = 5000\n",
        "outcomes = []\n",
        " \n",
        "start_time = time.time()\n",
        "\n",
        "counter = 0\n",
        "counter_dummy = 0\n",
        "counter_knock = 0\n",
        " \n",
        "for i in trange(N_sample):\n",
        "    M = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (N_assets, N)))\n",
        "    M = M + tilde_mu[:, None] * delta_t\n",
        "    M = np.cumsum(np.concatenate((np.zeros((N_assets, 1)), M), axis=1), axis=1)\n",
        "    M = np.multiply(np.exp(M), X_0[:, None])\n",
        "    \n",
        "    basket = np.sum(np.multiply(M, weights[:, None]), axis = 0)\n",
        "    \n",
        "    c = 1\n",
        "    if np.min(basket) <= L or np.max(basket) >= U:\n",
        "        counter += 1\n",
        "        c = 0\n",
        "    \n",
        "    if np.sum(basket) * delta_t / T >= strike:\n",
        "        counter_knock += 1\n",
        "        \n",
        "    if np.sum(basket) * delta_t / T >= strike and np.min(basket) > L and np.max(basket) < U:\n",
        "        counter_dummy += 1\n",
        "    \n",
        "    call_option = c * np.clip(np.sum(basket) * delta_t / T - strike, 0, None)\n",
        "    outcomes = outcomes + [np.exp(-r*T) * 100 * call_option]\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        " \n",
        "mean_mc = np.mean(outcomes)\n",
        "std_mc = np.std(outcomes)\n",
        "stderr_mc = std_mc / np.sqrt(N_sample)\n",
        " \n",
        "print(\"elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
        " \n",
        "print(\"Mean (MC): \", np.around(mean_mc, 4))\n",
        "print(\"Standard error (MC): \", np.around(stderr_mc, 4), \" (\", np.around(stderr_mc / mean_mc * 100, 2), \"% )\")\n",
        "print(\"Knock-outs: \", counter, \" (\", np.around(counter/N_sample * 100, 2), \"% )\")\n",
        "print(\"Positive payoffs: \", counter_knock, \" (\", np.around(counter_knock/N_sample * 100, 2), \"% )\")\n",
        "print(\"Positive and not knocked out: \", counter_dummy, \" (\", np.around(counter_dummy/N_sample * 100, 2), \"% )\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baDIxQuIEOGL"
      },
      "source": [
        "def func_lower(x):\n",
        "    greater = K.greater_equal(x, L)\n",
        "    greater = K.cast(greater, dtype=K.floatx())   \n",
        "    return greater\n",
        "\n",
        "def func_upper(x):\n",
        "    lower = K.less_equal(x, U)\n",
        "    lower = K.cast(lower, dtype=K.floatx())    \n",
        "    return lower"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdtrv9w1EOGM"
      },
      "source": [
        "def custom_activation(x):\n",
        "    return 1.7159*K.tanh(2*x/3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyinhcndEOGM"
      },
      "source": [
        "layers = []\n",
        "\n",
        "layer = Dense(N_assets, activation=custom_activation, trainable=True, \n",
        "              kernel_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              bias_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              name=str(0))\n",
        " \n",
        "layers = layers + [layer]\n",
        " \n",
        "layer = Dense(N_assets, activation=\"linear\", trainable=True, \n",
        "              kernel_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              bias_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              name=str(1))\n",
        " \n",
        "layers = layers + [layer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJkeZyaEEOGN"
      },
      "source": [
        "xtrain = ([np.zeros((N_train))] + # t_0\n",
        "          [delta_t*np.ones((N_train, N_assets))] + # time increment\n",
        "          [np.zeros((N_train, N_assets))] + # B_0\n",
        "          [np.tile(X_0, (N_train, 1))] + # X_0\n",
        "          [np.min(X_0) * np.ones((N_train))] + \n",
        "          [np.max(X_0) * np.ones((N_train))] + \n",
        "          [np.tile(weights/T, (N_train, 1))] + # basket weights\n",
        "          [np.zeros((N_train, N_assets))] + # initial value of the payoff\n",
        "          [np.zeros((N_train, N_assets))] + # initial value of the first part of the stoch exp\n",
        "          [np.zeros((N_train))] + # initial value of the second part of the stoch exp\n",
        "          [np.random.normal(0, np.sqrt(delta_t),(N_train, N_assets)) for i in range(N)]) # Brownian increments\n",
        " \n",
        "ytrain = np.zeros((N_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6STddBmEOGN"
      },
      "source": [
        "t_0 = Input(shape=(1, ))\n",
        "d_t = Input(shape=(N_assets, ))\n",
        "B_0 = Input(shape=(N_assets, ))\n",
        "X_start = Input(shape=(N_assets, ))\n",
        "X_min = Input(shape=(1, ))\n",
        "X_max = Input(shape=(1, ))\n",
        "wght = Input(shape=(N_assets, ))\n",
        " \n",
        "c_0 = Input(shape=(N_assets, ))\n",
        "c_1 = Input(shape=(N_assets, ))\n",
        "c_2 = Input(shape=(1, ))\n",
        " \n",
        "inputs = [t_0]+[d_t]+[B_0]+[X_start]+[X_min]+[X_max]+[wght]+[c_0]+[c_1]+[c_2]\n",
        " \n",
        "M_current = B_0 @ tf.linalg.matrix_transpose(K.constant(Sigma))\n",
        "X_current = X_start\n",
        "t_current = t_0\n",
        " \n",
        "for j in range(N):\n",
        "    \n",
        "    # Compute minimum and maximum of the basket\n",
        "    helper_k0 = Multiply()([wght, X_current])\n",
        "    helper_k1 = Lambda(lambda x: K.sum(x, axis=1))(helper_k0)\n",
        "    \n",
        "    X_min = Minimum()([X_min, helper_k1])\n",
        "    X_max = Maximum()([X_max, helper_k1])\n",
        "    \n",
        "    # Compute part of the basket\n",
        "    helper_b1 = Lambda(lambda x: x*delta_t)(X_current)\n",
        "    helper_b2 = Multiply()([wght, helper_b1])\n",
        "    c_0 = Add()([c_0, helper_b2])\n",
        "    \n",
        "    # Choose the drift\n",
        "    strategy = t_current\n",
        "    strategy = layers[0](strategy)\n",
        "    strategy = layers[1](strategy)\n",
        "    \n",
        "    # Draw a new increment of M\n",
        "    incr_B = Input(shape=(N_assets, ))\n",
        "    inputs = inputs + [incr_B]\n",
        "    incr_M = incr_B @ tf.linalg.matrix_transpose(K.constant(Sigma))\n",
        "    M_current = Add()([M_current, incr_M])\n",
        "    \n",
        "    # Compute first part of the measure change\n",
        "    helper_e1 = Multiply()([strategy, incr_M])\n",
        "    c_1 = Add()([c_1, helper_e1])\n",
        "    \n",
        "    # Compute second part of the measure change\n",
        "    helper_e2 = strategy @ tf.linalg.matrix_transpose(K.constant(Sigmaprime))\n",
        "    helper_e3 = Dot(axes=1)([strategy, helper_e2])\n",
        "    helper_e4 = Lambda(lambda x: x*delta_t)(helper_e3)\n",
        "    c_2 = Add()([c_2, helper_e4])\n",
        "\n",
        "    # Update time and X\n",
        "    t_current = Lambda(lambda x: x + delta_t)(t_current) \n",
        "    \n",
        "    helper_1 = Lambda(lambda x: tilde_mu * x)(t_current)\n",
        "    helper_2 = Add()([helper_1, M_current])\n",
        "    helper_3 = Lambda(lambda x: K.exp(x))(helper_2)\n",
        "    X_current = Multiply()([X_start, helper_3])\n",
        "    \n",
        "helper_e5 = Lambda(lambda x: -0.5 * K.sum(x, axis=1))(c_1)\n",
        "helper_e6 = Lambda(lambda x: 0.25 * x)(c_2)\n",
        " \n",
        "helper_e7 = Add()([helper_e5, helper_e6])\n",
        "helper_e8 = Lambda(lambda x: K.exp(x))(helper_e7)\n",
        " \n",
        "c_0 = Lambda(lambda x: K.sum(x, axis=1))(c_0)\n",
        "c_0 = Lambda(lambda x: K.relu(x - strike))(c_0)\n",
        " \n",
        "c_0 = Multiply()([c_0, helper_e8])\n",
        "\n",
        "X_min = Lambda(lambda x: func_lower(x))(X_min)\n",
        "X_max = Lambda(lambda x: func_upper(x))(X_max)\n",
        "\n",
        "he = Multiply()([X_min, X_max])\n",
        "c_0 = Multiply()([c_0, he])\n",
        "\n",
        "outputs = [c_0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxTilD7uEOGO"
      },
      "source": [
        "adam = optimizers.Adam(learning_rate=learnrate)\n",
        " \n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=adam, loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1-mfybjEOGO"
      },
      "source": [
        "#K.set_value(model.optimizer.learning_rate, 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvRN571VEOGO"
      },
      "source": [
        "stopping_rule = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kzOO0rfEOGP"
      },
      "source": [
        "history = model.fit(x=xtrain, y=ytrain, epochs=500, verbose = 1, batch_size=1024, validation_split=0.2, callbacks=[stopping_rule])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBZNmMd1EOGQ"
      },
      "source": [
        "# print(history.history.keys())\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(history.history['mse'])\n",
        "plt.plot(history.history['val_mse'])\n",
        "plt.title('model loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcc3qGcmEOGQ"
      },
      "source": [
        "# for i in range(25):\n",
        "#     print(i)\n",
        "#     print(model.layers[i].get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvDn_5qUEOGR"
      },
      "source": [
        "# Visualizing the feedforward neural network\n",
        "\n",
        "model_test = keras.Sequential()\n",
        "model_test.add(Dense(N_assets, activation=custom_activation, name=\"layer1\", input_shape=(1, )))\n",
        "model_test.add(Dense(N_assets, activation=\"linear\", name=\"layer2\"))\n",
        " \n",
        "model_test.build()\n",
        " \n",
        "model_test.layers[0].set_weights(model.layers[7].get_weights())\n",
        "model_test.layers[1].set_weights(model.layers[13].get_weights())\n",
        " \n",
        "t = np.linspace(0, T, N+1)\n",
        "learnedstrat = model_test.predict(t)\n",
        " \n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(t, learnedstrat)\n",
        "plt.xlabel(\"t\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOENh58PEOGR"
      },
      "source": [
        "# Visualizing the drift\n",
        "\n",
        "normdrift = 0\n",
        "driftdelta = []\n",
        "driftcomponent = [np.zeros((N_assets))]\n",
        "driftdummy = np.zeros((N_assets))\n",
        "\n",
        "for i in range(N):\n",
        "    normdrift = normdrift + np.dot(np.transpose(learnedstrat[i,:]), np.dot(Sigmaprime, learnedstrat[i,:])) * delta_t\n",
        "\n",
        "    driftdummy = driftdummy + np.dot(Sigmaprime, learnedstrat[i,:]) * delta_t\n",
        "    driftcomponent = driftcomponent + [driftdummy]\n",
        "\n",
        "    driftdelta = driftdelta + [np.dot(Sigmaprime, learnedstrat[i,:]) * delta_t]\n",
        "\n",
        "driftdelta = np.transpose(np.asarray(driftdelta))\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(t, driftcomponent)\n",
        "plt.xlabel(\"t\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOscjXFEEOGR"
      },
      "source": [
        "# Visualizing the drift adjustment of M for one sample path\n",
        "\n",
        "M_random = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (N_assets, N)))\n",
        "\n",
        "M_MC = np.cumsum(np.concatenate((np.zeros((N_assets, 1)), M_random), axis=1), axis=1)\n",
        "M_IS = np.cumsum(np.concatenate((np.zeros((N_assets, 1)), M_random + driftdelta[:,:N]), axis=1), axis=1)\n",
        "\n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.plot(t, np.transpose(M_MC), color = \"black\", alpha = 0.50, label=\"without drift adjustment\")\n",
        "plt.plot(t, np.transpose(M_IS), color = \"black\", label=\"with drift adjustment\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NShcqU_yEOGS"
      },
      "source": [
        "N_reps = 10\n",
        "N_sample = 5000\n",
        " \n",
        "start_time = time.time()\n",
        " \n",
        "means_MC = []\n",
        "means_IS = []\n",
        " \n",
        "stderr_MC = []\n",
        "stderr_IS = []\n",
        "\n",
        "breachprob_MC = []\n",
        "breachprob_IS = [] \n",
        "    \n",
        "varratio = []\n",
        "\n",
        "counter_pos_MC = []\n",
        "counter_pos_IS = []\n",
        " \n",
        "for k in trange(N_reps):\n",
        "\n",
        "    outcomes_MC = []\n",
        "    outcomes_IS = []\n",
        "    \n",
        "    counter_MC = 0\n",
        "    counter_IS = 0\n",
        "    \n",
        "    outcomes_pos_MC = 0\n",
        "    outcomes_pos_IS = 0\n",
        "    \n",
        "    for i in range(N_sample):\n",
        "        \n",
        "        M_random = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (N_assets, N)))\n",
        "    \n",
        "        ##########\n",
        "    \n",
        "        M_MC = M_random + tilde_mu[:, None] * delta_t\n",
        "        M_MC = np.cumsum(np.concatenate((np.zeros((N_assets, 1)), M_MC), axis=1), axis=1)\n",
        "        M_MC = np.multiply(np.exp(M_MC), X_0[:, None])\n",
        "        \n",
        "        basket = np.sum(np.multiply(M_MC, weights[:, None]), axis = 0)\n",
        "        c = 1\n",
        "        if np.min(basket) <= L or np.max(basket) >= U:\n",
        "            counter_MC += 1\n",
        "            c = 0\n",
        "        \n",
        "        basket = np.sum(basket) * delta_t / T\n",
        "        if basket > strike:\n",
        "            outcomes_pos_MC += 1\n",
        "        \n",
        "        call_MC = c * np.clip(basket - strike, 0, None)\n",
        "        outcomes_MC = outcomes_MC + [np.exp(-r*T) * 100 * call_MC]\n",
        " \n",
        "        ##########\n",
        "\n",
        "        M_0 = M_random + driftdelta[:,:N]\n",
        "\n",
        "        M_IS = M_0 + tilde_mu[:, None] * delta_t\n",
        "        M_IS = np.cumsum(np.concatenate((np.zeros((N_assets, 1)), M_IS), axis=1), axis=1)\n",
        "        M_IS = np.multiply(np.exp(M_IS), X_0[:, None])\n",
        "        \n",
        "        C0 = np.sum(np.sum(np.multiply(np.transpose(learnedstrat[0:N,:]), M_random), axis=1), axis=0)\n",
        "        C1 = normdrift\n",
        "        adjustment = np.exp(-1 * C0 - 0.5 * C1)\n",
        "        \n",
        "        basket = np.sum(np.multiply(M_IS, weights[:, None]), axis = 0)\n",
        "        c = 1\n",
        "        if np.min(basket) <= L or np.max(basket) >= U:\n",
        "            counter_IS += 1\n",
        "            c = 0\n",
        "            \n",
        "        basket = np.sum(basket) * delta_t / T\n",
        "        if basket > strike:\n",
        "            outcomes_pos_IS += 1\n",
        "    \n",
        "        call_IS = c * np.clip(basket - strike, 0, None)\n",
        "        outcomes_IS = outcomes_IS + [np.exp(-r*T) * 100 * call_IS * adjustment]\n",
        "        \n",
        "        ##########\n",
        "    \n",
        "    means_MC = means_MC + [np.mean(outcomes_MC)]\n",
        "    means_IS = means_IS + [np.mean(outcomes_IS)]\n",
        "    \n",
        "    stderr_MC = stderr_MC + [np.std(outcomes_MC) / np.sqrt(N_sample)]\n",
        "    stderr_IS = stderr_IS + [np.std(outcomes_IS) / np.sqrt(N_sample)]\n",
        "    \n",
        "    breachprob_MC = breachprob_MC + [counter_MC / N_sample * 100]\n",
        "    breachprob_IS = breachprob_IS + [counter_IS / N_sample * 100]\n",
        "    \n",
        "    varratio = varratio + [np.var(outcomes_MC) / np.var(outcomes_IS)]\n",
        "    \n",
        "    counter_pos_MC = counter_pos_MC + [outcomes_pos_MC / N_sample * 100]\n",
        "    counter_pos_IS = counter_pos_IS + [outcomes_pos_IS / N_sample * 100]\n",
        "    \n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"total elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_esihUmEOGS"
      },
      "source": [
        "print(\"Average MC estimate: \", np.around(np.mean(means_MC), 4))\n",
        "print(\"Average IS estimate: \", np.around(np.mean(means_IS), 4))\n",
        "print(\"Average standard error (MC): \", np.around(np.mean(stderr_MC), 4), \" (\", np.around(np.mean(stderr_MC) / np.mean(means_MC) * 100, 2), \"% )\")\n",
        "print(\"Average standard error (IS): \", np.around(np.mean(stderr_IS), 4), \" (\", np.around(np.mean(stderr_IS) / np.mean(means_IS) * 100, 2), \"% )\")\n",
        "print(\"Average variance ratio: \", np.around(np.mean(varratio)))\n",
        "print(\"Average prob of hitting the barrier (MC): \", np.around(np.mean(breachprob_MC), 2), \"%\")\n",
        "print(\"Average prob of hitting the barrier (IS): \", np.around(np.mean(breachprob_IS), 2), \"%\")\n",
        "print(\"Average probability of positive payoff (MC): \", np.around(np.mean(counter_pos_MC), 2), \"%\")\n",
        "print(\"Average probability of positive payoff (IS): \", np.around(np.mean(counter_pos_IS), 2), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyzDBv39EOGT"
      },
      "source": [
        "print(\"mean MC estimate:  \", np.around(np.mean(means_MC), 4))\n",
        "print(\"mean IS estimate: \", np.around(np.mean(means_IS), 4))\n",
        " \n",
        "bins = np.linspace(0.00, 0.10, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(means_MC, bins, color=\"darkorchid\", alpha=0.5, label=\"MC estimates\")\n",
        "plt.hist(means_IS, bins, color=\"goldenrod\", alpha=0.5, label=\"IS estimates\")\n",
        "plt.axvline(np.mean(means_MC), color=\"darkorchid\", linewidth=2)\n",
        "plt.axvline(np.mean(means_IS), color=\"goldenrod\", linewidth=2)\n",
        "plt.title(\"MC estimates with and without importance sampling\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cHIuKIwEOGT"
      },
      "source": [
        "print(\"mean MC estimate standard error:  \", np.around(np.mean(stderr_MC), 4))\n",
        "print(\"mean IS estimate standard error: \", np.around(np.mean(stderr_IS), 4))\n",
        " \n",
        "bins = np.linspace(0.00, 0.1, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(stderr_MC, bins, color=\"darkorchid\", alpha=0.5, label=\"MC estimates\")\n",
        "plt.hist(stderr_IS, bins, color=\"goldenrod\", alpha=0.5, label=\"IS estimates\")\n",
        "plt.axvline(np.mean(stderr_MC), color=\"darkorchid\", linewidth=2)\n",
        "plt.axvline(np.mean(stderr_IS), color=\"goldenrod\", linewidth=2)\n",
        "plt.title(\"MC estimates standard errors with and without importance sampling\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x4mHwSnEOGT"
      },
      "source": [
        "print(\"mean MC probability of positive payoff:  \", np.around(np.mean(counter_pos_MC), 2))\n",
        "print(\"mean IS probability of positive payoff: \", np.around(np.mean(counter_pos_IS), 2))\n",
        " \n",
        "bins = np.linspace(0.00, 100.00, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(counter_pos_MC, bins, color=\"darkorchid\", alpha=0.5, label=\"MC estimates\")\n",
        "plt.hist(counter_pos_IS, bins, color=\"goldenrod\", alpha=0.5, label=\"IS estimates\")\n",
        "plt.axvline(np.mean(counter_pos_MC), color=\"darkorchid\", linewidth=2)\n",
        "plt.axvline(np.mean(counter_pos_IS), color=\"goldenrod\", linewidth=2)\n",
        "plt.title(\"MC probabilities of positive payoff\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZblndVHEOGU"
      },
      "source": [
        "bins = np.linspace(0.00, 150.00, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(varratio, bins, color=\"darkorchid\", alpha=0.5)\n",
        "plt.title(\"Variance ratios\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEKmrER3EOGU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}