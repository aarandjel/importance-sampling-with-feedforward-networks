{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Heston_arithmetic_asian_basket_call.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarandjel/importance-sampling-with-feedforward-networks/blob/main/Heston_arithmetic_asian_basket_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM565F2w5MIo"
      },
      "source": [
        "# Importance sampling for option pricing with feedforward neural networks\n",
        "\n",
        "In this Jupyter notebook, we study the problem of reducing the standard error in Monte Carlo simulations when pricing path-dependent options through suitable changes of measure which are induced by feedforward networks.\n",
        "\n",
        "We consider an arithmetic Asian basket call option in a multivariate Heston model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE7Asy8_gm4i"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.linalg import norm\n",
        "from tqdm.notebook import trange\n",
        "from numpy import savetxt, loadtxt\n",
        " \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import initializers, optimizers, layers\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, Subtract, Multiply, Lambda, Add, Dot, Reshape, Cropping1D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        " \n",
        "print('Python version: ', sys.version)\n",
        "print('Tensorflow version: ', tf.__version__)\n",
        "print('Keras version: ', keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrI1YR7Zgm4j"
      },
      "source": [
        "T = 1\n",
        "N = 252\n",
        "delta_t = T/N\n",
        "strike = 60.0\n",
        "r = 0.05\n",
        "N_assets = 5\n",
        "N_train = 3*10**5\n",
        "learnrate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDFpc7P9Iv2m"
      },
      "source": [
        "# X_0 = np.around(np.random.uniform(low=40.0, high=50.0, size=(N_assets)),0)\n",
        "# mu = np.around(np.random.uniform(low=0.0, high=0.10, size=(N_assets)),4)\n",
        "# V_0 = np.around(np.random.uniform(low=0.10, high=0.30, size=(N_assets)),4)\n",
        "# m = np.around(np.random.uniform(low=0.10, high=0.30, size=(N_assets)),4)\n",
        "# Theta = np.multiply(np.identity(N_assets), np.around(np.random.uniform(low=10.0, high=20.0, size=(N_assets))))\n",
        "# Sigma = np.around(np.random.uniform(low=-0.3, high=0.3, size=(2*N_assets, 2*N_assets)), 4)\n",
        "\n",
        "# savetxt(\"mSVX_0.csv\", X_0, delimiter=\",\")\n",
        "# savetxt(\"mSVmu.csv\", mu, delimiter=\",\")\n",
        "# savetxt(\"mSVV_0.csv\", V_0, delimiter=\",\")\n",
        "# savetxt(\"mSVm.csv\", m, delimiter=\",\")\n",
        "# savetxt(\"mSVTheta.csv\", Theta, delimiter=\",\")\n",
        "# savetxt(\"mSVSigma.csv\", Sigma, delimiter=\",\")\n",
        "\n",
        "X_0 = loadtxt(\"mSVX_0.csv\", delimiter=\",\")\n",
        "mu = loadtxt(\"mSVmu.csv\", delimiter=\",\")\n",
        "V_0 = loadtxt(\"mSVV_0.csv\", delimiter=\",\")\n",
        "m = loadtxt(\"mSVm.csv\", delimiter=\",\")\n",
        "Theta = loadtxt(\"mSVTheta.csv\", delimiter=\",\")\n",
        "Sigma = loadtxt(\"mSVSigma.csv\", delimiter=\",\")\n",
        "\n",
        "# X_0 = loadtxt(\"https://raw.githubusercontent.com/aarandjel/importance-sampling-with-feedforward-networks/main/mBSX_0.csv\", delimiter=\",\")\n",
        "# mu = loadtxt(\"https://raw.githubusercontent.com/aarandjel/importance-sampling-with-feedforward-networks/main/mBSmu.csv\", delimiter=\",\")\n",
        "# Sigma = loadtxt(\"https://raw.githubusercontent.com/aarandjel/importance-sampling-with-feedforward-networks/main/mBSSigma.csv\", delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8RZiEs3Iv2n"
      },
      "source": [
        "Sigmaprime = np.dot(Sigma, np.transpose(Sigma)) # This is the variance-covariance matrix of $M_{1} = \\Sigma B_{1}$\n",
        "\n",
        "weights = np.divide(mu, np.sqrt(np.diag(Sigmaprime)[:N_assets]))\n",
        "weights = weights / np.sum(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmZ4IV74Iv2n"
      },
      "source": [
        "# Check Feller's condition\n",
        "print(np.min(2*np.multiply(np.diag(Theta), m)-np.diag(Sigmaprime)[N_assets:]) > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LMZ8UkXIv2o"
      },
      "source": [
        "# Visualizing the correlation matrix of $M_{1}$\n",
        "v = np.sqrt(np.diag(Sigmaprime))\n",
        "outer_v = np.outer(v,v)\n",
        "Rho = Sigmaprime / outer_v\n",
        "Rho[Sigmaprime == 0] = 0\n",
        "\n",
        "f, ax = plt.subplots(figsize=(9, 13))\n",
        "\n",
        "heatmap = sns.heatmap(Rho, square = True, linewidths = .5, cmap=\"RdBu\", \n",
        "                      cbar_kws = {'shrink': .4, \"ticks\" : [-1, -.5, 0, 0.5, 1]},\n",
        "                      vmin = -1, vmax = 1, annot = True, annot_kws = {\"size\": 12})\n",
        "\n",
        "ax.set_yticklabels(\"\")\n",
        "ax.set_xticklabels(\"\")\n",
        "\n",
        "sns.set_style({'xtick.bottom': True}, {'ytick.left': True})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tdBcAQF8jWz",
        "scrolled": true
      },
      "source": [
        "X = [X_0]\n",
        "X_current = X_0\n",
        "\n",
        "V = [V_0]\n",
        "V_current = V_0\n",
        "\n",
        "for i in range(N):\n",
        "    increment = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (2*N_assets)))\n",
        "    \n",
        "    drift = np.multiply(mu, X_current) * delta_t\n",
        "    diffusion = np.multiply(np.multiply(np.sqrt(V_current), X_current), increment[:N_assets])\n",
        "    \n",
        "    X_current = X_current + drift + diffusion\n",
        "    X = X + [X_current]\n",
        "    \n",
        "    V_current = V_current + np.dot(Theta, m-V_current) * delta_t + np.multiply(np.sqrt(V_current), increment[N_assets:])\n",
        "    V_current = np.maximum(V_current, 0)\n",
        "    V = V + [V_current]\n",
        "\n",
        "t = np.linspace(0, T, N+1) \n",
        "\n",
        "fig, axs = plt.subplots(2, figsize=(18, 10))\n",
        "axs[0].plot(X)\n",
        "axs[1].plot(V)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV8KRELp8jW0"
      },
      "source": [
        "N_sample = 5000\n",
        "outcomes = []\n",
        "counter = 0\n",
        " \n",
        "start_time = time.time()\n",
        "\n",
        "for j in trange(N_sample):\n",
        "    X = [X_0]\n",
        "    X_current = X_0\n",
        "    V = [V_0]\n",
        "    V_current = V_0\n",
        "\n",
        "    for i in range(N):\n",
        "        increment = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (2*N_assets)))\n",
        "\n",
        "        drift = np.multiply(mu, X_current) * delta_t\n",
        "        diffusion = np.multiply(np.multiply(np.sqrt(V_current), X_current), increment[:N_assets])\n",
        "\n",
        "        X_current = X_current + drift + diffusion\n",
        "        X = X + [X_current]\n",
        "\n",
        "        V_current = V_current + np.dot(Theta, m-V_current) * delta_t + np.multiply(np.sqrt(V_current), increment[N_assets:])\n",
        "        V_current = np.maximum(V_current, 0)\n",
        "        V = V + [V_current]\n",
        "\n",
        "    basket = np.sum(np.dot(np.transpose(weights), np.sum(X, axis=0) * delta_t / T))\n",
        "    \n",
        "    if basket > strike:\n",
        "        counter += 1\n",
        "        \n",
        "    call_option = np.clip(basket - strike, 0, None)\n",
        "    outcomes = outcomes + [np.exp(-r*T) * 100 * call_option]\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "mean_mc = np.mean(outcomes)\n",
        "std_mc = np.std(outcomes)\n",
        "stderr_mc = std_mc / np.sqrt(N_sample)\n",
        "\n",
        "print(\"elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
        "\n",
        "print(\"Mean (MC): \", np.around(mean_mc, 4))\n",
        "print(\"Standard error (MC): \", np.around(stderr_mc, 4), \" (\", np.around(stderr_mc / mean_mc * 100, 2), \"% )\")\n",
        "print(\"Probability of positive payoff (MC): \", np.around(counter / N_sample * 100, 2), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yywjcL-5XoyH"
      },
      "source": [
        "def custom_activation(x):\n",
        "    return 1.7159*K.tanh(2*x/3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2jvOJq_8jW2"
      },
      "source": [
        "layers = []\n",
        " \n",
        "layer = Dense(2*N_assets, activation=custom_activation, trainable=True, \n",
        "              kernel_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              bias_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              name=str(0))\n",
        " \n",
        "layers = layers + [layer]\n",
        " \n",
        "layer = Dense(2*N_assets, activation=\"linear\", trainable=True, \n",
        "              kernel_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              bias_initializer=initializers.RandomNormal(0.0, 1.0), \n",
        "              name=str(1))\n",
        " \n",
        "layers = layers + [layer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4fbKual8jW2"
      },
      "source": [
        "xtrain = ([np.zeros((N_train))] + # t_0\n",
        "          [np.tile(mu, (N_train, 1))] + # mu\n",
        "          [delta_t*np.ones((N_train, N_assets))] + # time increment\n",
        "          [0*np.ones((N_train, 2*N_assets))] + # B_0\n",
        "          [np.tile(X_0, (N_train, 1))] + # X_0\n",
        "          [np.tile(V_0, (N_train, 1))] + # V_0\n",
        "          [np.tile(weights / T, (N_train, 1))] + # basket weights\n",
        "          [np.zeros((N_train, N_assets))] + # initial value of the payoff\n",
        "          [np.zeros((N_train, 2*N_assets))] + # initial value of the first part of the stoch exp\n",
        "          [np.zeros((N_train))] + # initial value of the second part of the stoch exp\n",
        "          [np.random.normal(0,np.sqrt(delta_t),(N_train, 2*N_assets)) for i in range(N)]) # Brownian increments\n",
        " \n",
        "ytrain = np.zeros((N_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss3hKR2Y8jW3"
      },
      "source": [
        "t_0 = Input(shape=(1, ))\n",
        "drft = Input(shape=(N_assets, ))\n",
        "d_t = Input(shape=(N_assets, ))\n",
        " \n",
        "B_0 = Input(shape=(2*N_assets, ))\n",
        "X_start = Input(shape=(N_assets, ))\n",
        "V_start = Input(shape=(N_assets, ))\n",
        " \n",
        "wght = Input(shape=(N_assets, ))\n",
        " \n",
        "c_0 = Input(shape=(N_assets, ))\n",
        "c_1 = Input(shape=(2*N_assets, ))\n",
        "c_2 = Input(shape=(1, ))\n",
        " \n",
        "inputs = [t_0]+[drft]+[d_t]+[B_0]+[X_start]+[V_start]+[wght]+[c_0]+[c_1]+[c_2]\n",
        " \n",
        "M_current = B_0 @ tf.linalg.matrix_transpose(K.constant(Sigma))\n",
        "X_current = X_start\n",
        "V_current = V_start\n",
        "t_current = t_0\n",
        " \n",
        "for j in range(N):\n",
        "    \n",
        "    # Compute part of the basket\n",
        "    helper_b1 = Lambda(lambda x: x*delta_t)(X_current)\n",
        "    helper_b2 = Multiply()([wght, helper_b1])\n",
        "    c_0 = Add()([c_0, helper_b2])\n",
        "    \n",
        "    # Choose the drift\n",
        "    strategy = t_current\n",
        "    strategy = layers[0](strategy)\n",
        "    strategy = layers[1](strategy)\n",
        "    \n",
        "    # Draw a new increment of M\n",
        "    incr_B = Input(shape=(2*N_assets, ))\n",
        "    inputs = inputs + [incr_B]\n",
        "    incr_M = incr_B @ tf.linalg.matrix_transpose(K.constant(Sigma))\n",
        "    M_current = Add()([M_current, incr_M])\n",
        "    \n",
        "    ### Split up the increments\n",
        "    first_half, second_half = tf.split(incr_M, 2, axis = 1)\n",
        "    \n",
        "    # Compute first part of the measure change\n",
        "    helper_e1 = Multiply()([strategy, incr_M])\n",
        "    c_1 = Add()([c_1, helper_e1])\n",
        "    \n",
        "    # Compute second part of the measure change\n",
        "    helper_e2 = strategy @ tf.linalg.matrix_transpose(K.constant(Sigmaprime))\n",
        "    helper_e3 = Dot(axes=1)([strategy, helper_e2])\n",
        "    helper_e4 = Lambda(lambda x: x*delta_t)(helper_e3)\n",
        "    c_2 = Add()([c_2, helper_e4])\n",
        "    \n",
        "    # Update time\n",
        "    t_current = Lambda(lambda x: x + delta_t)(t_current)\n",
        "    \n",
        "    # Update X\n",
        "    helper_x0 = Multiply()([drft, X_current])\n",
        "    helper_x1 = Lambda(lambda x: x * delta_t)(helper_x0)\n",
        "    \n",
        "    helper_x2 = Multiply()([K.sqrt(V_current), X_current])\n",
        "    helper_x3 = Multiply()([helper_x2, first_half])\n",
        "    \n",
        "    helper_x4 = Add()([helper_x1, helper_x3])\n",
        "    X_current = Add()([X_current, helper_x4])\n",
        "    \n",
        "    # Update V\n",
        "    helper_v0 = Lambda(lambda x: m-x)(V_current)\n",
        "    helper_v1 = helper_v0 @ tf.linalg.matrix_transpose(K.constant(Theta))\n",
        "    helper_v2 = Lambda(lambda x: x * delta_t)(helper_v1)\n",
        "    \n",
        "    helper_v3 = Multiply()([K.sqrt(V_current), second_half])\n",
        "    \n",
        "    helper_v4 = Add()([helper_v2, helper_v3])\n",
        "    V_current = Add()([V_current, helper_v4])\n",
        "    V_current = K.relu(V_current)\n",
        "    \n",
        "helper_y1 = Lambda(lambda x: -0.5 * K.sum(x, axis=1))(c_1)\n",
        "helper_y2 = Lambda(lambda x: 0.25 * x)(c_2)\n",
        " \n",
        "helper_y3 = Add()([helper_y1, helper_y2])\n",
        "helper_y4 = Lambda(lambda x: K.exp(x))(helper_y3)\n",
        " \n",
        "c_0 = Lambda(lambda x: K.sum(x, axis=1))(c_0)\n",
        "c_0 = Lambda(lambda x: K.relu(x - strike))(c_0)\n",
        " \n",
        "c_0 = Multiply()([c_0, helper_y4])\n",
        " \n",
        "outputs = [c_0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVjbnmxQ8jW3"
      },
      "source": [
        "adam = optimizers.Adam(learning_rate=learnrate)\n",
        " \n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=adam, loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz65W7Gs8jW3"
      },
      "source": [
        "# K.set_value(model.optimizer.learning_rate, 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHPgsjdsIv2s"
      },
      "source": [
        "stopping_rule = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfPTI7vQIv2t"
      },
      "source": [
        "history = model.fit(x=xtrain, y=ytrain, epochs=500, verbose = 1, batch_size=1024, validation_split=0.2, callbacks=[stopping_rule])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrNWdCTE8jW3"
      },
      "source": [
        "# print(history.history.keys())\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(history.history['mse'])\n",
        "plt.plot(history.history['val_mse'])\n",
        "plt.title('model loss (MSE)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1mKBkJ2Iv2u"
      },
      "source": [
        "# for i in range(5000):\n",
        "#     print(i)\n",
        "#     print(model.layers[i].get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCsmJhNO8jW4"
      },
      "source": [
        "# Visualizing the feedforward neural network\n",
        "\n",
        "model_test = keras.Sequential()\n",
        "model_test.add(Dense(2*N_assets, activation=custom_activation, name=\"layer1\", input_shape=(1, )))\n",
        "model_test.add(Dense(2*N_assets, activation=\"linear\", name=\"layer2\"))\n",
        " \n",
        "model_test.build()\n",
        " \n",
        "model_test.layers[0].set_weights(model.layers[4012].get_weights())\n",
        "model_test.layers[1].set_weights(model.layers[4017].get_weights())\n",
        " \n",
        "t = np.linspace(0, T, N+1)\n",
        "learnedstrat = model_test.predict(t)\n",
        " \n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(t, learnedstrat)\n",
        "plt.xlabel(\"t\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E4oLriZIv2u"
      },
      "source": [
        "# Visualizing the drift\n",
        "\n",
        "normdrift = 0\n",
        "driftdelta = []\n",
        "driftcomponent = [np.zeros((2*N_assets))]\n",
        "driftdummy = np.zeros((2*N_assets))\n",
        "\n",
        "for i in range(N):\n",
        "    normdrift = normdrift + np.dot(np.transpose(learnedstrat[i,:]), np.dot(Sigmaprime, learnedstrat[i,:])) * delta_t\n",
        "\n",
        "    driftdummy = driftdummy + np.dot(Sigmaprime, learnedstrat[i,:]) * delta_t\n",
        "    driftcomponent = driftcomponent + [driftdummy]\n",
        "\n",
        "    driftdelta = driftdelta + [np.dot(Sigmaprime, learnedstrat[i,:]) * delta_t]\n",
        "\n",
        "driftdelta = np.asarray(driftdelta)\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(t, driftcomponent)\n",
        "plt.xlabel(\"t\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBP-5HWhIv2v"
      },
      "source": [
        "# Visualizing the drift adjustment of M for one sample path\n",
        "\n",
        "M_random = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (2*N_assets, N)))\n",
        "\n",
        "M_MC = np.cumsum(np.concatenate((np.zeros((2*N_assets, 1)), M_random), axis=1), axis=1)\n",
        "M_IS = np.cumsum(np.concatenate((np.zeros((2*N_assets, 1)), M_random + np.transpose(driftdelta)[:,:N]), axis=1), axis=1)\n",
        "\n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.plot(t, np.transpose(M_MC), color = \"black\", alpha = 0.50, label=\"without drift adjustment\")\n",
        "plt.plot(t, np.transpose(M_IS), color = \"black\", label=\"with drift adjustment\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uZjej1NIv2v"
      },
      "source": [
        "N_reps = 1\n",
        "N_sample = 5000\n",
        " \n",
        "start_time = time.time()\n",
        " \n",
        "means_MC = []\n",
        "means_IS = []\n",
        " \n",
        "stderr_MC = []\n",
        "stderr_IS = []\n",
        " \n",
        "varratio = []\n",
        "\n",
        "counter_pos_MC = []\n",
        "counter_pos_IS = []\n",
        "\n",
        "for k in trange(N_reps):\n",
        "    \n",
        "    outcomes_MC = []\n",
        "    outcomes_IS = []\n",
        "    \n",
        "    outcomes_pos_MC = 0\n",
        "    outcomes_pos_IS = 0\n",
        "\n",
        "    for j in range(N_sample):\n",
        "    \n",
        "        X_MC = [X_0]\n",
        "        X_current_MC = X_0\n",
        "\n",
        "        V_MC = [V_0]\n",
        "        V_current_MC = V_0\n",
        "    \n",
        "        X_IS = [X_0]\n",
        "        X_current_IS = X_0\n",
        "\n",
        "        V_IS = [V_0]\n",
        "        V_current_IS = V_0\n",
        "\n",
        "        C0 = 0\n",
        "\n",
        "        for i in range(N):\n",
        "            increment = np.dot(Sigma, np.random.normal(0, np.sqrt(delta_t), (2*N_assets)))\n",
        "    \n",
        "            ########## MC\n",
        "            drift = np.multiply(mu, X_current_MC) * delta_t\n",
        "            diffusion = np.multiply(np.multiply(np.sqrt(V_current_MC), X_current_MC), increment[:N_assets])\n",
        "    \n",
        "            X_current_MC = X_current_MC + drift + diffusion\n",
        "            X_MC = X_MC + [X_current_MC] \n",
        "            \n",
        "            V_current_MC = V_current_MC + np.dot(Theta, m-V_current_MC) * delta_t + np.multiply(np.sqrt(V_current_MC), increment[N_assets:])\n",
        "            V_current_MC = np.maximum(V_current_MC, 0)\n",
        "            V_MC = V_MC + [V_current_MC]     \n",
        "        \n",
        "            ########## IS\n",
        "            increment_IS = increment + driftdelta[i]\n",
        "            \n",
        "            drift = np.multiply(mu, X_current_IS) * delta_t\n",
        "            diffusion = np.multiply(np.multiply(np.sqrt(V_current_IS), X_current_IS), increment_IS[:N_assets])\n",
        "    \n",
        "            X_current_IS = X_current_IS + drift + diffusion\n",
        "            X_IS = X_IS + [X_current_IS] \n",
        "        \n",
        "            V_current_IS = V_current_IS + np.dot(Theta, m-V_current_IS) * delta_t + np.multiply(np.sqrt(V_current_IS), increment_IS[N_assets:])\n",
        "            V_current_IS = np.maximum(V_current_IS, 0)\n",
        "            V_IS = V_IS + [V_current_IS] \n",
        "    \n",
        "            C0 = C0 - np.dot(learnedstrat[i,:], increment)\n",
        "    \n",
        "        adjustment = np.exp(C0 - 0.5 * normdrift)\n",
        "        \n",
        "        basket_MC = np.sum(np.dot(np.transpose(weights), np.sum(X_MC, axis=0) * delta_t / T))\n",
        "        \n",
        "        if basket_MC > strike:\n",
        "            outcomes_pos_MC += 1\n",
        "        \n",
        "        basket_IS = np.sum(np.dot(np.transpose(weights), np.sum(X_IS, axis=0) * delta_t / T))\n",
        "        \n",
        "        if basket_IS > strike:\n",
        "            outcomes_pos_IS += 1\n",
        "    \n",
        "        call_MC = np.clip(basket_MC - strike, 0, None)\n",
        "        call_IS = np.clip(basket_IS - strike, 0, None)\n",
        "\n",
        "        outcomes_MC = outcomes_MC + [np.exp(-r*T) * 100 * call_MC]\n",
        "        outcomes_IS = outcomes_IS + [np.exp(-r*T) * 100 * call_IS * adjustment]\n",
        "        \n",
        "    ##########\n",
        "    means_MC = means_MC + [np.mean(outcomes_MC)]\n",
        "    means_IS = means_IS + [np.mean(outcomes_IS)]\n",
        "    \n",
        "    stderr_MC = stderr_MC + [np.std(outcomes_MC) / np.sqrt(N_sample)]\n",
        "    stderr_IS = stderr_IS + [np.std(outcomes_IS) / np.sqrt(N_sample)]\n",
        "    \n",
        "    varratio = varratio + [np.var(outcomes_MC) / np.var(outcomes_IS)]\n",
        "    \n",
        "    counter_pos_MC = counter_pos_MC + [outcomes_pos_MC / N_sample * 100]\n",
        "    counter_pos_IS = counter_pos_IS + [outcomes_pos_IS / N_sample * 100]\n",
        "    \n",
        "    print(k, \": \", np.around(np.var(outcomes_MC) / np.var(outcomes_IS)))\n",
        "    \n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"total elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLtRZxmYIv2w"
      },
      "source": [
        "print(\"Average MC estimate: \", np.around(np.mean(means_MC), 4))\n",
        "print(\"Average IS estimate: \", np.around(np.mean(means_IS), 4))\n",
        "print(\"Average standard error (MC): \", np.around(np.mean(stderr_MC), 4), \" (\", np.around(np.mean(stderr_MC) / np.mean(means_MC) * 100, 2), \"% )\")\n",
        "print(\"Average standard error (IS): \", np.around(np.mean(stderr_IS), 4), \" (\", np.around(np.mean(stderr_IS) / np.mean(means_IS) * 100, 2), \"% )\")\n",
        "print(\"Average variance ratio: \", np.around(np.mean(varratio)))\n",
        "print(\"Average probability of positive payoff (MC): \", np.around(np.mean(counter_pos_MC), 2), \"%\")\n",
        "print(\"Average probability of positive payoff (IS): \", np.around(np.mean(counter_pos_IS), 2), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TCuYN39gm4n"
      },
      "source": [
        "print(\"mean MC estimate:  \", np.around(np.mean(means_MC), 4))\n",
        "print(\"mean IS estimate: \", np.around(np.mean(means_IS), 4))\n",
        " \n",
        "bins = np.linspace(0.50, 2.00, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(means_MC, bins, color=\"darkorchid\", alpha=0.5, label=\"MC estimates\")\n",
        "plt.hist(means_IS, bins, color=\"goldenrod\", alpha=0.5, label=\"IS estimates\")\n",
        "plt.axvline(np.mean(means_MC), color=\"darkorchid\", linewidth=2)\n",
        "plt.axvline(np.mean(means_IS), color=\"goldenrod\", linewidth=2)\n",
        "plt.title(\"MC estimates with and without importance sampling\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0W7ukcW8jW6"
      },
      "source": [
        "print(\"mean MC estimate standard error:  \", np.around(np.mean(stderr_MC), 4))\n",
        "print(\"mean IS estimate standard error: \", np.around(np.mean(stderr_IS), 4))\n",
        " \n",
        "bins = np.linspace(0.00, 0.40, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(stderr_MC, bins, color=\"darkorchid\", alpha=0.5, label=\"MC estimates\")\n",
        "plt.hist(stderr_IS, bins, color=\"goldenrod\", alpha=0.5, label=\"IS estimates\")\n",
        "plt.axvline(np.mean(stderr_MC), color=\"darkorchid\", linewidth=2)\n",
        "plt.axvline(np.mean(stderr_IS), color=\"goldenrod\", linewidth=2)\n",
        "plt.title(\"MC estimates standard errors with and without importance sampling\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X040QiIuIv2x"
      },
      "source": [
        "print(\"mean MC probability of positive payoff:  \", np.around(np.mean(counter_pos_MC), 2))\n",
        "print(\"mean IS probability of positive payoff: \", np.around(np.mean(counter_pos_IS), 2))\n",
        " \n",
        "bins = np.linspace(0.00, 100.00, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(counter_pos_MC, bins, color=\"darkorchid\", alpha=0.5, label=\"MC estimates\")\n",
        "plt.hist(counter_pos_IS, bins, color=\"goldenrod\", alpha=0.5, label=\"IS estimates\")\n",
        "plt.axvline(np.mean(counter_pos_MC), color=\"darkorchid\", linewidth=2)\n",
        "plt.axvline(np.mean(counter_pos_IS), color=\"goldenrod\", linewidth=2)\n",
        "plt.title(\"MC probabilities of positive payoff\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnJzWcs-8jW6"
      },
      "source": [
        "bins = np.linspace(0.00, 500.00, 100)\n",
        " \n",
        "plt.figure(figsize=(18, 10)) \n",
        "plt.hist(varratio, bins, color=\"darkorchid\", alpha=0.5)\n",
        "plt.title(\"Variance ratios\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabsBKP_Iv2y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cid_SntOIv2y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}